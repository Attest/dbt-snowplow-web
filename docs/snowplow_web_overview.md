{% docs __snowplow_dbt_web__ %}
# Snowplow dbt Web Model
Welcome to the documentation site for the Snowplow dbt Web Model. The Snowplow dbt Web Model is a fully incremental model, that transforms raw web event data generated by Snowplow trackers into a series of derived tables of varying levels of aggregation.

## Overview

This model consists of a series of modules, each producing a table which serves as the input to the next module. The 'standard' modules are:

- Base: Performs the incremental logic (ADD LINK TO incremental logic section), outputting the table `snowplow_web_base_events_this_run` which contains a de-duped data set of all events required for the current run of the model. 
- Page Views: Aggregates event level data to a page view level, `page_view_id`.
- Sessions: Aggregates page view level data to a session level, `domain_sessionid`.
- Users: Aggregates session level data to a users level, `domain_userid`. 

The 'standard' modules can be thought of as source code for the core logic of the model, which Snowplow maintains. These modules carry out the incremental logic in such a way as custom modules can be written to plug into the model's structure, without needing to write a parallel incremental logic. We recommend that all customisations are written in this way, which allows us to safely maintain and roll out updates to the model, without impact on dependent custom sql.

Each module produces a table which acts as the input to the subsequent module (the `_this_run` tables), and updates a production table - with the exception of the Base module, which takes atomic data as its input, and does not update a production table.

## Configuration

### Source Data
This package will by default will assume your Snowplow events data is contained in the `atomic` schema of your [target.database](https://docs.getdbt.com/docs/running-a-dbt-project/using-the-command-line-interface/configure-your-profile). In order to change this, please add the following to your `dbt_project.yml` file:

```yml
# dbt_project.yml
...
vars:
  snowplow__atomic_schema: schema_with_snowplow_events
  snowplow__database: database_with_snowplow_events
```

### Contexts
The web model has the option to join in data from the following 3 Snowplow enrichments:
- [IAB enrichment](https://docs.snowplowanalytics.com/docs/enriching-your-data/available-enrichments/iab-enrichment/)
- [UA Parser enrichment](https://docs.snowplowanalytics.com/docs/enriching-your-data/available-enrichments/ua-parser-enrichment/)
- [YAUAA enrichment](https://docs.snowplowanalytics.com/docs/enriching-your-data/available-enrichments/yauaa-enrichment/)

By default these are **all disabled** in the web model. Assuming you have the enrichments turned on in your Snowplow pipeline, to enable within the web model please add the following to your `dbt_project.yml` file:
```yml
# dbt_project.yml
...
vars:
  snowplow__enable_iab: true
  snowplow__enable_ua: true
  snowplow__enable_yauaa: true
```

### Filtering Data
Within the web model you can specify both `start_date` at which to start processing events and the `app_id`'s to filter for. By default the `start_date` is set to `2020-01-01` and all `app_id`'s are selected. To change this please add the following to your `dbt_project.yml` file:
```yml
# dbt_project.yml
...
vars:
  snowplow__start_date: 'yyyy-mm-dd'
  snowplow__app_id: ['my_app_1','my_app_2']
```

### Page Pings
The web model processes page ping events to calculate web page engagement times. Assuming you have page pings enabled within the [Snowplow JavaScript Tracker](https://docs.snowplowanalytics.com/docs/collecting-data/collecting-from-own-applications/javascript-trackers/javascript-tracker/javascript-tracker-v3/tracking-events/#activity-tracking-page-pings), please align the `min_visit_length` and `heartbeat` variables to your specific implementation by adding the following to your `dbt_project.yml` file:
```yml
# dbt_project.yml
...
vars:
  snowplow__min_visit_length: 5
  snowplow__heartbeat: 10
```

### Further Configuration
This package makes use of a series of other variables, which are all set to the recommend values for the operation of the web model. Depending on your use case, you might want to override these values by adding to your `dbt_project.yml` file.

`snowplow__lookback_window_hours`:  Default 6. The number of hours to look before the latest event processed - to account for late arriving data, which comes out of order.

`snowplow__backfill_limit_days`:    Default 30. The maximum numbers of days of new data to be processed since the latest event processed. Please refer to the back-filling section for more details. ADD LINK

`snowplow__session_lookback_days`:  Default 365. Number of days to limit scan on `snowplow_web_base_sessions_lifecycle` manifest. Exists to improve performance of model when we have a lot of sessions. Should be set to as large a number as practical.

`snowplow__days_late_allowed`:      Default 3. Number of days for which we should include late data. If the difference between collector tstamps for the session start and new event is greater than this value, data for that session will not be processed.

`snowplow__upsert_lookback_days`:   Default 30. Number of day to look back over the incremental production table during the upsert. Where performance is not a concern, should be set to as long a value as possible. Having too short a period can result in duplicates. Please see the materialization section for more details. ADD LINK

`snowplow__ua_bot_filter`:          Default `True`. Configuration to filter out bots via useragent string pattern match.

{% enddocs %}
